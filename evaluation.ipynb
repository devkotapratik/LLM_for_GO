{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.traversal.depth_first_search import dfs_tree\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_DIR = Path(\"/home/informatics/pdevkota\")\n",
    "BASE_DIR = Path(\".\").absolute()\n",
    "DATA_DIR = Path.joinpath(BASE_DIR, \"data\")\n",
    "DATASET_DIR = Path.joinpath(DATA_DIR, \"model_input\", \"dataset\")\n",
    "OUT_DIR = Path.joinpath(DATA_DIR, \"GO_Category\")\n",
    "GO_FILE = Path.joinpath(OUT_DIR, \"all_GO.json\")\n",
    "HIERARCHY_FILE = Path.joinpath(OUT_DIR, \"GO_DirectParents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FALCON_MODEL = \"tiiuae/falcon-7b-instruct\"\n",
    "MODEL_DIR = Path.joinpath(Path(\"./MODELS\"), Path(FALCON_MODEL.upper().replace(\"-\", \"_\")).stem) #\"MODELS/FALCON_7B_INSTRUCT\"\n",
    "\n",
    "PREDICTION_DIR = Path.joinpath(Path(\"/home/informatics/pdevkota\"), \"qlora\", \"predictions\", \"FALCON_40B\")\n",
    "# PREDICTION_DIR = Path.joinpath(Path(\".\"), \"predictions\", MODEL_DIR.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GO_FILE, \"r\") as f:\n",
    "    all_contents = json.load(f)\n",
    "\n",
    "go_info = dict(sorted(((i[\"id\"], i) for i in all_contents), key=lambda x: x[0]))\n",
    "hierarchy_data = pd.read_csv(HIERARCHY_FILE)\n",
    "\n",
    "go_ids = list(go_info.keys())\n",
    "go_concepts = [go_info.get(i).get(\"name\") for i in go_ids]\n",
    "concept_to_id = dict((k.replace(\"obsolete \", \"\"), v) for k, v in zip(go_concepts, go_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_digraph = nx.from_pandas_edgelist(hierarchy_data, source=\"Child\", target=\"Parent\", create_using=nx.classes.digraph.DiGraph)\n",
    "subsumers = dict((i,list(\n",
    "    set(np.array(dfs_tree(onto_digraph, i).edges()).flatten().tolist() + [i]) - \n",
    "    set([\"root\"]))) for i in onto_digraph.nodes())\n",
    "print(\"Number of nodes:\", onto_digraph.number_of_nodes(), \"\\nNumber of edges:\", onto_digraph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path.joinpath(OUT_DIR, \"primary_secondary.json\"), \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    primary_ids, secondary_ids = data[\"primary_ids\"], data[\"secondary_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file = Path.joinpath(PREDICTION_DIR, \"outputs.json\")\n",
    "try:\n",
    "    assert prediction_file.is_file()\n",
    "    with open(prediction_file, \"r\") as f:\n",
    "        outputs = json.load(f)\n",
    "except AssertionError as assert_err:\n",
    "    output_files = sorted(PREDICTION_DIR.iterdir(), key=lambda x: x.stem.split(\"_\")[-1])\n",
    "    output_files = [i for i in output_files if i.suffix == \".json\" and i.stem[-1].isnumeric()]\n",
    "    outputs = []\n",
    "    for file in output_files:\n",
    "        with open(file, \"r\") as f:\n",
    "            outputs.extend(json.load(f))\n",
    "    with open(prediction_file, \"w\") as f:\n",
    "        json.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(term1, term2):\n",
    "    if \"GO\" in term1 and \"GO\" in term2:\n",
    "        term1 = term1.replace(\"B-\", \"\").replace(\"I-\", \"\")\n",
    "        term2 = term2.replace(\"B-\", \"\").replace(\"I-\", \"\")\n",
    "        t1 = set(subsumers.get(term1, term1))\n",
    "        t2 = set(subsumers.get(term2, term2))\n",
    "        if len(set.union(t1, t2)) > 0:\n",
    "            simj=len(set.intersection(t1, t2))/len(set.union(t1, t2))\n",
    "        else:\n",
    "            simj = 0.0\n",
    "    else:\n",
    "        simj = 0.0\n",
    "    return simj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms_and_concepts_new(example):\n",
    "    keys = [\"term\", \"concept\"]\n",
    "    temp_keys = keys.copy()\n",
    "    reqd_kv = dict()\n",
    "    for kv in example.split(\"\\n\"):\n",
    "        pair = [i.strip() for i in kv.split(\":\", maxsplit=1)]\n",
    "        if len(pair) <=1: continue #return [(\"none\", \"none\")]\n",
    "        for i in range(len(temp_keys)):\n",
    "            if temp_keys[i] in pair[0].lower():\n",
    "                reqd_kv.update({temp_keys[i]: pair[1]})\n",
    "                temp_keys.pop(i)\n",
    "                break\n",
    "    for key in keys:\n",
    "        items = [i.strip() for i in reqd_kv.get(key, \"none\").replace(\"[\", \"\").replace(\"]\", \"\").split(\"|\")]\n",
    "        reqd_kv.update({key: items})\n",
    "    terms_n_concepts = [(x, y) for x, y in zip(reqd_kv.get(\"term\", \"none\"), reqd_kv.get(\"concept\", \"none\"))]\n",
    "    return terms_n_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substring(string):\n",
    "    return re.findall(r'\\b\\w+\\b', string.lower())\n",
    "\n",
    "def substring_match(str1, str2, type:str=\"intersection\"):\n",
    "    if type == \"intersection\":\n",
    "        return set(substring(str1)) & set(substring(str2))\n",
    "    if type == \"difference\":\n",
    "        return set(substring(str1)) - set(substring(str2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoid_hallucination_new(json_data):\n",
    "    \"\"\"Given a dictionary with input sentence in 'pre' key and response in 'response' key,\n",
    "    this module returns the list of terms and their go_ids after removing terms that are not\n",
    "    present in the input sentence, thus mitigating the effect of hallucination\"\"\"\n",
    "    response_data = get_terms_and_concepts_new(json_data[\"response\"])\n",
    "    response_count = Counter([i[0].lower() for i in response_data])\n",
    "    if len(response_count) == 1 and response_count.get(\"none\"):\n",
    "        return [(\"none\", \"none\")]\n",
    "    for i_response, count in response_count.items():\n",
    "        i_match = list(re.finditer(re.escape(i_response), json_data[\"pre\"], re.IGNORECASE))\n",
    "        hallucination_idx = [idx for idx, i in enumerate(response_data) if \n",
    "                             i[0].lower() == i_response][len(i_match):]\n",
    "        for h_idx in hallucination_idx[::-1]:\n",
    "            response_data.pop(h_idx)\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = []\n",
    "for out_idx, output in enumerate(outputs):\n",
    "    # expected_data = get_terms_and_concepts(output[\"output\"])\n",
    "    expected_data = get_terms_and_concepts_new(output[\"output\"])\n",
    "    temp_expected = [(i[0].lower(), i[1]) for i in expected_data]\n",
    "    temp_response = avoid_hallucination_new(output)\n",
    "    match_idx = []\n",
    "    for idx, i_response in enumerate(temp_response):\n",
    "        idy = 0\n",
    "        while len(temp_expected):\n",
    "            matched_set = substring_match(i_response[0], temp_expected[idy][0])\n",
    "            if len(matched_set):\n",
    "                comparison.append(\n",
    "                    (out_idx, i_response, temp_expected[idy])\n",
    "                )\n",
    "                temp_expected.pop(idy)\n",
    "                match_idx.append(idx)\n",
    "                break\n",
    "            idy += 1\n",
    "            if idy >= len(temp_expected):\n",
    "                break\n",
    "    temp_response = [i for idx, i in enumerate(temp_response) if idx not in match_idx]\n",
    "    match = [(idx, i) for idx, i in enumerate(temp_response) if\n",
    "             len(substring_match(i[0], output[\"pre\"].lower()))]\n",
    "    y_pred = [i for idx, i in enumerate(temp_response) if idx in [j[0] for j in match]]\n",
    "    for i_response in temp_response:\n",
    "        comparison.append((out_idx, i_response, (\"none\", \"none\")))\n",
    "    for i_expected in temp_expected:\n",
    "        comparison.append((out_idx, (\"none\", \"none\"), i_expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "model_name = \"allenai-specter\"\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_ef = SentenceTransformerEmbeddingFunction(model_name=model_name)\n",
    "go_concept_collection = chroma_client.create_collection(name=\"go_concept\", embedding_function=sent_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_embeddings = [i.tolist() for i in model.encode(go_concepts)]\n",
    "go_concept_collection.add(\n",
    "    ids=go_ids,\n",
    "    embeddings=go_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = pd.DataFrame(comparison)\n",
    "pd_data.columns = [\"Position\", \"Prediction\", \"Ground Truth\"]\n",
    "pd_data = pd_data[[\"Position\", \"Ground Truth\", \"Prediction\"]]\n",
    "pd_data.drop(\n",
    "    pd_data[\n",
    "        (pd_data[\"Prediction\"] == (\"none\", \"none\")) & \n",
    "        (pd_data[\"Ground Truth\"] == (\"none\", \"none\"))\n",
    "    ].index, inplace=True\n",
    ")\n",
    "pd_data[\"Ground_ID\"] = pd_data[\"Ground Truth\"].apply(lambda x: concept_to_id.get(x[1], \"O\"))\n",
    "pd_data.drop(\n",
    "    pd_data[\n",
    "        (pd_data[\"Ground_ID\"] == \"O\") &\n",
    "        (pd_data[\"Ground Truth\"] != (\"none\", \"none\"))\n",
    "    ].index, inplace=True)\n",
    "pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_comparison = []\n",
    "for i_row in range(len(pd_data)):\n",
    "    data = pd_data.iloc[i_row]\n",
    "    pos = data[\"Position\"]\n",
    "    gt, pred, gt_id = data[\"Ground Truth\"], data[\"Prediction\"], data[\"Ground_ID\"]\n",
    "    gt_go, pred_go = gt[1], pred[1]\n",
    "    gt_words, pred_words = substring(gt[0]), substring(pred[0])\n",
    "    temp = []\n",
    "    try:\n",
    "        for i in range(max(len(gt_words), len(pred_words))):\n",
    "            if i >= len(gt_words):\n",
    "                temp.append((pos, (\"none\", \"none\"), (pred_words[i], pred_go), \"O\"))\n",
    "            elif i >= len(pred_words):\n",
    "                temp.append((pos, (gt_words[i], gt_go), (\"none\", \"none\"), gt_id))\n",
    "            else:\n",
    "                temp.append((pos, (gt_words[i], gt_go), (pred_words[i], pred_go), gt_id))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        print(data)\n",
    "        print(pos, gt_words, pred_words)\n",
    "        input()\n",
    "    expanded_comparison.extend(temp)\n",
    "\n",
    "ext_data = pd.DataFrame(expanded_comparison, columns=[\"Position\", \"Ground Truth\", \"Prediction\", \"Ground_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ext_data[\"Prediction\"].apply(lambda x: x[1]).tolist()\n",
    "pred_ids = go_concept_collection.query(\n",
    "    query_texts=queries,\n",
    "    n_results=1\n",
    ")[\"ids\"]\n",
    "pred_ids = [i[0] for i in pred_ids]\n",
    "pred_ids = [x if y != \"none\" else \"O\" for x, y in zip(pred_ids, queries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_data[\"Prediction_ID\"] = pred_ids\n",
    "ext_data.columns = [\"Position\", \"Ground Truth\", \"Prediction\", \"True_Id\", \"Pred_Id\"]\n",
    "ext_data[\"Semantic Similarity\"] = ext_data.apply(lambda x: get_sim(x[\"True_Id\"], x[\"Pred_Id\"]), axis=1)\n",
    "ext_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_report = classification_report(\n",
    "    ext_data[\"True_Id\"], \n",
    "    ext_data[\"Pred_Id\"],\n",
    "    digits=4,\n",
    "    zero_division=False\n",
    ")\n",
    "true_report = [i.split(\" \") for i in true_report.splitlines()]\n",
    "temp = sorted(true_report[2:-4], key=lambda x: int(x[-1]), reverse=True)\n",
    "true_report = true_report[:2] + temp + true_report[-4:]\n",
    "true_report = \"\\n\".join(\" \".join(i) for i in true_report)\n",
    "print(dict(F1_Score=float(true_report.splitlines()[-1].split()[-2]), Semantic_Similarity=round(ext_data[\"Semantic Similarity\"].mean(), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
